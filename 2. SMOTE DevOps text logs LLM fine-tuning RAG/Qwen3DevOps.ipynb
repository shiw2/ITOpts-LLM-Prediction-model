{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb7dcf6",
   "metadata": {},
   "source": [
    "# Data Merge and labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4980221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merge successful, total 15921814 records\n",
      "Abnormal ratio: 0.57%, Warning ratio: 6.32%, Normal: 14824942, Warning: 1006779, Abnormal: 90093\n",
      "abnormal_sample: 11, warning_sample: 126, normal_sample: 1863\n",
      "Sampled 2000 records (abnormal + warning + normal)\n",
      "Sampled data saved to 'data/sourcedata/messages-sampled.jsonl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Merge \n",
    "folder = \"data/sourcedata\"\n",
    "files = [os.path.join(folder, f) for f in os.listdir(folder) if f.startswith(\"messages-\")]\n",
    "records = []\n",
    "for f in files:\n",
    "    with open(f, 'r', encoding='utf-8') as fh:\n",
    "        for line in fh:\n",
    "            ts, host, text = line.strip().split(' ', 2)\n",
    "            records.append({'timestamp': ts, 'text': text})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"Data merge successful, total {len(df)} records\")\n",
    "\n",
    "# Label (normal/abnormal/warning)\n",
    "def label_fn(txt):\n",
    "    if re.search(r'(?i)error', txt):\n",
    "        return 'abnormal'\n",
    "    elif re.search(r'(?i)(alert|fail|warning)', txt):\n",
    "        return 'warning'\n",
    "    else:\n",
    "        return 'normal'\n",
    "\n",
    "df['label'] = df['text'].apply(label_fn)\n",
    "\n",
    "# Statistics for normal, abnormal, and warning\n",
    "total = len(df)\n",
    "n_abnormal = (df['label'] == 'abnormal').sum()\n",
    "n_warning = (df['label'] == 'warning').sum()\n",
    "n_normal = (df['label'] == 'normal').sum()\n",
    "abnormal_ratio = n_abnormal / total if total > 0 else 0\n",
    "warning_ratio = n_warning / total if total > 0 else 0\n",
    "\n",
    "print(f\"Abnormal ratio: {abnormal_ratio:.2%}, Warning ratio: {warning_ratio:.2%}, Normal: {n_normal}, Warning: {n_warning}, Abnormal: {n_abnormal}\")\n",
    "\n",
    "# Get 500 samples with the same abnormal ratio and warning ratio\n",
    "n_sample = 2000\n",
    "n_abnormal = int(n_sample * abnormal_ratio)\n",
    "n_warning = int(n_sample * warning_ratio)\n",
    "n_normal = n_sample - n_abnormal - n_warning\n",
    "\n",
    "# Sampled data\n",
    "abnormal = df[df['label'] == 'abnormal']\n",
    "warning = df[df['label'] == 'warning']\n",
    "normal = df[df['label'] == 'normal']\n",
    "\n",
    "abnormal_sample = abnormal.sample(n=min(n_abnormal, len(abnormal)), random_state=42)\n",
    "warning_sample = warning.sample(n=min(n_warning, len(warning)), random_state=42)\n",
    "normal_sample = normal.sample(n=min(n_normal, len(normal)), random_state=42)\n",
    "\n",
    "# Sort by timestamp\n",
    "abnormal_sample = abnormal_sample.sort_values(by='timestamp')\n",
    "warning_sample = warning_sample.sort_values(by='timestamp')\n",
    "normal_sample = normal_sample.sort_values(by='timestamp')\n",
    "\n",
    "# Combine into a new dataset\n",
    "sampled = pd.concat([abnormal_sample, warning_sample, normal_sample]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"abnormal_sample: {len(abnormal_sample)}, warning_sample: {len(warning_sample)}, normal_sample: {len(normal_sample)}\")\n",
    "print(f\"Sampled {len(sampled)} records (abnormal + warning + normal)\")\n",
    "\n",
    "# Save as JSONL\n",
    "sampled.to_json('data/sourcedata/messages-sampled.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "print(\"Sampled data saved to 'data/sourcedata/messages-sampled.jsonl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6d9e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            timestamp  \\\n",
      "0    2025-05-12 03:49:22.535042+08:00   \n",
      "1    2025-05-12 04:17:49.646275+08:00   \n",
      "3    2025-05-12 04:30:22.240842+08:00   \n",
      "4    2025-05-12 04:44:35.856701+08:00   \n",
      "5    2025-05-12 04:51:10.625776+08:00   \n",
      "...                               ...   \n",
      "1995 2025-06-02 02:02:43.864290+08:00   \n",
      "1996 2025-06-02 02:24:13.065783+08:00   \n",
      "1997 2025-06-02 02:40:38.274371+08:00   \n",
      "1998 2025-06-02 02:52:19.383783+08:00   \n",
      "1999 2025-06-02 02:57:20.693974+08:00   \n",
      "\n",
      "                                                   text   label  \n",
      "0       systemd: Starting Session 1237560 of user root.  normal  \n",
      "1     python: - ** ---------- .> results:     elasti...  normal  \n",
      "3        systemd: Started Session 1239069 of user root.  normal  \n",
      "4                                       python: [tasks]  normal  \n",
      "5     python: --- * ***  * -- Linux-3.10.0-1160.el7....  normal  \n",
      "...                                                 ...     ...  \n",
      "1995                                    python: [tasks]  normal  \n",
      "1996  xinetd[4580]: EXIT: mysql_status status=0 pid=...  normal  \n",
      "1997  xinetd[4580]: EXIT: mysql_status status=0 pid=...  normal  \n",
      "1998  python: - *** --- * --- .> concurrency: 4 (pre...  normal  \n",
      "1999  systemd-logind: New session 2384882 of user root.  normal  \n",
      "\n",
      "[1863 rows x 3 columns]\n",
      "                            timestamp  \\\n",
      "2    2025-05-12 04:18:04.755651+08:00   \n",
      "23   2025-05-12 07:56:26.228343+08:00   \n",
      "72   2025-05-12 19:32:16.678099+08:00   \n",
      "86   2025-05-13 00:15:26.177845+08:00   \n",
      "88   2025-05-13 00:30:14.261837+08:00   \n",
      "...                               ...   \n",
      "1951 2025-06-01 16:28:11.695054+08:00   \n",
      "1957 2025-06-01 17:57:50.969743+08:00   \n",
      "1974 2025-06-01 21:47:19.009931+08:00   \n",
      "1982 2025-06-01 23:34:29.977343+08:00   \n",
      "1990 2025-06-02 01:04:50.384159+08:00   \n",
      "\n",
      "                                                   text    label  \n",
      "2                  systemd: infi-celery.service failed.  warning  \n",
      "23                 systemd: infi-celery.service failed.  warning  \n",
      "72    systemd: infi-celery.service: main process exi...  warning  \n",
      "86    systemd: infi-celery.service: main process exi...  warning  \n",
      "88    systemd: Unit infi-celery.service entered fail...  warning  \n",
      "...                                                 ...      ...  \n",
      "1951  systemd: infi-celery.service: main process exi...  warning  \n",
      "1957  python: /usr/lib/python2.7/site-packages/celer...  warning  \n",
      "1974  python: /usr/lib/python2.7/site-packages/celer...  warning  \n",
      "1982  systemd: Unit infi-celery.service entered fail...  warning  \n",
      "1990  systemd: infi-celery.service: main process exi...  warning  \n",
      "\n",
      "[126 rows x 3 columns]\n",
      "                            timestamp  \\\n",
      "411  2025-05-16 13:49:37.117442+08:00   \n",
      "596  2025-05-18 07:58:08.437301+08:00   \n",
      "600  2025-05-18 08:39:48.983734+08:00   \n",
      "775  2025-05-20 08:27:28.508428+08:00   \n",
      "776  2025-05-20 08:30:13.531274+08:00   \n",
      "780  2025-05-20 09:04:57.207540+08:00   \n",
      "1362 2025-05-26 21:02:15.003037+08:00   \n",
      "1383 2025-05-27 02:31:12.726671+08:00   \n",
      "1418 2025-05-27 09:57:27.260290+08:00   \n",
      "1783 2025-05-31 04:59:46.583194+08:00   \n",
      "1921 2025-06-01 08:53:27.406094+08:00   \n",
      "\n",
      "                                                   text     label  \n",
      "411   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "596   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "600   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "775   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "776   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "780   named[7310]: error (network unreachable) resol...  abnormal  \n",
      "1362  named[7310]: error (network unreachable) resol...  abnormal  \n",
      "1383  infinity[4110052]: an error occurred while req...  abnormal  \n",
      "1418  named[7310]: error (network unreachable) resol...  abnormal  \n",
      "1783  named[7310]: error (network unreachable) resol...  abnormal  \n",
      "1921  infinity[4139103]: an error occurred while req...  abnormal  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"data/sourcedata/messages-sampled.jsonl\", lines=True)\n",
    "print(df[df['label'] == 'normal'])\n",
    "print(df[df['label'] == 'warning'])\n",
    "print(df[df['label'] == 'abnormal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcea5a",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f48144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1000\n",
      "Number of test samples: 1000\n",
      "Train set label counts:\n",
      "label\n",
      "normal      935\n",
      "warning      59\n",
      "abnormal      6\n",
      "Name: count, dtype: int64\n",
      "Test set label counts:\n",
      "label\n",
      "normal      928\n",
      "warning      67\n",
      "abnormal      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data/sourcedata/messages-sampled.jsonl', lines=True)\n",
    "\n",
    "# Time order\n",
    "df = df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "# train/test 8:2\n",
    "train_size = int(len(df) * 0.5)\n",
    "train_df = df.iloc[:train_size].reset_index(drop=True)\n",
    "test_df = df.iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df)}\")\n",
    "print(f\"Number of test samples: {len(test_df)}\")\n",
    "\n",
    "os.makedirs('data/sampledatasets', exist_ok=True)\n",
    "train_df.to_json('data/sampledatasets/messages-train.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "test_df.to_json('data/sampledatasets/messages-test.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "print(\"Train set label counts:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"Test set label counts:\")\n",
    "print(test_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d088a2",
   "metadata": {},
   "source": [
    "# Inbalance Data -- Synthetic Minority Oversampling Technique(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec109f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled training set label counts:\n",
      "label\n",
      "0    935\n",
      "1    935\n",
      "2    935\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the original dataset and training set\n",
    "df = pd.read_json('data/sourcedata/messages-sampled.jsonl', lines=True)\n",
    "train_df = pd.read_json('data/sampledatasets/messages-train.jsonl', lines=True)\n",
    "\n",
    "# Label mapping\n",
    "label_to_id = {'normal': 0, 'warning': 1, 'abnormal': 2}\n",
    "if train_df['label'].dtype == 'object':\n",
    "    train_df['label'] = train_df['label'].map(label_to_id)\n",
    "if df['label'].dtype == 'object':\n",
    "    df['label'] = df['label'].map(label_to_id)\n",
    "\n",
    "# Get the number of normal samples as target\n",
    "target_count = train_df['label'].value_counts().max()  \n",
    "\n",
    "# Step 1: Handle abnormal class (random sampling from original data)\n",
    "abnormal_count = train_df['label'].value_counts().get(2, 0) \n",
    "warning_count = train_df['label'].value_counts().get(1, 0)\n",
    "if abnormal_count < warning_count:\n",
    "    additional_abnormal = df[df['label'] == 2].sample(n=target_count - abnormal_count, random_state=42, replace=False)\n",
    "    train_df = pd.concat([train_df, additional_abnormal]).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Apply SMOTE to warning class\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(train_df['text']).toarray()\n",
    "y = train_df['label'].values\n",
    "\n",
    "smote = SMOTE(random_state=42, sampling_strategy={1: target_count}, k_neighbors=1)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 3: Convert TF-IDF features back to text\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "original_embeddings = embedder.encode(train_df['text'].tolist())\n",
    "resampled_texts = vectorizer.inverse_transform(X_res)\n",
    "resampled_texts = [' '.join(text) for text in resampled_texts]\n",
    "resampled_embeddings = embedder.encode(resampled_texts)\n",
    "\n",
    "# Find the most similar original text for each synthetic sample\n",
    "similarities = cosine_similarity(resampled_embeddings, original_embeddings)\n",
    "most_similar_indices = similarities.argmax(axis=1)\n",
    "train_df_resampled = train_df.iloc[most_similar_indices].copy()\n",
    "train_df_resampled['label'] = y_res\n",
    "\n",
    "# Step 4: Ensure abnormal class is fully supplemented with random samples\n",
    "abnormal_indices = train_df_resampled[train_df_resampled['label'] == 2].index\n",
    "if len(abnormal_indices) < target_count:\n",
    "    additional_abnormal_resampled = df[df['label'] == 2].sample(n=target_count - len(abnormal_indices), random_state=42, replace=True)\n",
    "    train_df_resampled = pd.concat([train_df_resampled, additional_abnormal_resampled]).reset_index(drop=True)\n",
    "\n",
    "# Save the resampled training set\n",
    "train_df_resampled.to_json('data/sampledatasets/messages-train-resampled.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "# Print the new label distribution\n",
    "print(\"Resampled training set label counts:\")\n",
    "print(train_df_resampled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f6001",
   "metadata": {},
   "source": [
    "# LLM & Fine-Tunning & RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7aa98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31e4a5203e04f21b4f96644a61c6de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2a868e07fe44bbba43f0879d64d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\weish\\AppData\\Local\\Temp\\ipykernel_9864\\1313607647.py:236: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化Trainer...\n",
      "训练数据集大小: 2805\n",
      "测试数据集大小: 1000\n",
      "数据集列: ['timestamp', 'text', 'labels', 'input_ids', 'attention_mask']\n",
      "样本批次键: dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "labels shape: torch.Size([2])\n",
      "input_ids shape: torch.Size([2, 128])\n",
      "attention_mask shape: torch.Size([2, 128])\n",
      "测试compute_metrics函数...\n",
      "Debug: predictions shape: (4, 3)\n",
      "Debug: labels shape: (4,)\n",
      "Debug: computed metrics: {'accuracy': 0.0, 'f1': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
      "compute_metrics测试成功: {'accuracy': 0.0, 'f1': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
      "开始训练...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1053' max='1053' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1053/1053 09:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.601700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估...\n",
      "RAG预测结果:\n",
      "Accuracy: 0.9290\n",
      "F1 Score: 0.8958\n",
      "Precision: 0.9290\n",
      "Recall: 0.9290\n",
      "\n",
      "混淆矩阵:\n",
      "[[928   0   0]\n",
      " [ 66   1   0]\n",
      " [  5   0   0]]\n",
      "\n",
      "标签映射: {0: 'normal', 1: 'warning', 2: 'abnormal'}\n",
      "normal 类准确率: 1.0000\n",
      "warning 类准确率: 0.0149\n",
      "abnormal 类准确率: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\Qwen3DevOps\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# 1. Data Loading\n",
    "train_df = pd.read_json('data/sampledatasets/messages-train-resampled.jsonl', lines=True)\n",
    "test_df = pd.read_json('data/sampledatasets/messages-test.jsonl', lines=True)\n",
    "\n",
    "# Verify format\n",
    "def verify(df):\n",
    "    assert 'text' in df.columns and 'label' in df.columns, \"JSONL must contain 'text' and 'label'\"\n",
    "\n",
    "verify(train_df)\n",
    "verify(test_df)\n",
    "\n",
    "# Label mapping\n",
    "label_to_id = {'normal': 0, 'warning': 1, 'abnormal': 2}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "for df in (train_df, test_df):\n",
    "    if df['label'].dtype == 'object':\n",
    "        df['label'] = df['label'].map(label_to_id)\n",
    "num_labels = len(label_to_id)\n",
    "\n",
    "# Class weights\n",
    "y = train_df['label'].values\n",
    "classes = np.unique(y)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to('cuda')\n",
    "\n",
    "# 2. Build FAISS index for RAG KB\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "kb = [\n",
    "    {\"text\": item['text'], \"solution\": item['solution']} \n",
    "    for item in [\n",
    "        {\n",
    "        \"text\": \"systemd: infi-celery.service: main process exited, code=exited, status=1/FAILURE\",\n",
    "        \"solution\": \"Check the infi-celery service log, verify configuration and dependencies, and try restarting the service.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"systemd: infi-celery.service holdoff time over, scheduling restart.\",\n",
    "        \"solution\": \"The service will automatically restart after an exception. Investigate the root cause of the abnormal exit.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"systemd: infi-celery.service: control process exited, code=exited status=1\",\n",
    "        \"solution\": \"Check the control process log and verify service configuration and permissions.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"systemd: Started Infinity Celery Worker Service.\",\n",
    "        \"solution\": \"The service started successfully. No action required.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"systemd-logind: Removed session\",\n",
    "        \"solution\": \"User session was removed. This is usually a normal operation.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"xinetd[4580]: EXIT: mysql_status status=0\",\n",
    "        \"solution\": \"MySQL status check is normal. No action required.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"xinetd[4580]: EXIT: zk_status status=0\",\n",
    "        \"solution\": \"Zookeeper status check is normal. No action required.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"python: /usr/lib/python2.7/site-packages/celery/platforms.py:796: RuntimeWarning: You're running the worker with superuser privileges: this is\",\n",
    "        \"solution\": \"It is not recommended to run celery worker as root. Please use a regular user.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"infinity[4139103]: an error occurred while requesting bindings <urlopen error [Errno 111] Connection refused>\",\n",
    "        \"solution\": \"Check network connectivity and ensure the target service port is open.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"kill: kill: cannot find process\",\n",
    "        \"solution\": \"The target process does not exist. Please verify the process ID.\"\n",
    "    }\n",
    "    ]\n",
    "]\n",
    "kb_texts = [entry['text'] for entry in kb]\n",
    "kb_embs = embedder.encode(kb_texts)\n",
    "dim = kb_embs.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(kb_embs)\n",
    "\n",
    "def retrieve_solutions(text, k=3):\n",
    "    emb = embedder.encode([text])\n",
    "    D, I = index.search(np.array(emb), k)\n",
    "    return \" \".join(kb[i]['solution'] for i in I[0])\n",
    "\n",
    "# 3. Prepare datasets\n",
    "d_train = Dataset.from_pandas(train_df)\n",
    "d_test = Dataset.from_pandas(test_df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-0.6B')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "d_train = d_train.map(tokenize_fn, batched=True)\n",
    "d_test = d_test.map(tokenize_fn, batched=True)\n",
    "\n",
    "# Rename & format\n",
    "d_train = d_train.rename_column('label', 'labels')\n",
    "d_test = d_test.rename_column('label', 'labels')\n",
    "for ds in (d_train, d_test):\n",
    "    ds.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# 4. Model & LoRA setup\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'Qwen/Qwen3-0.6B', num_labels=num_labels\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    lora_dropout=0.1,\n",
    "    bias='none'\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.to('cuda')\n",
    "\n",
    "# 5. 修复的Metrics函数\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    try:\n",
    "        predictions, labels = eval_pred\n",
    "        print(f\"Debug: predictions shape: {predictions.shape if hasattr(predictions, 'shape') else type(predictions)}\")\n",
    "        print(f\"Debug: labels shape: {labels.shape if hasattr(labels, 'shape') else type(labels)}\")\n",
    "        \n",
    "        # 确保predictions是numpy数组\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        \n",
    "        # 转换为numpy数组\n",
    "        if not isinstance(predictions, np.ndarray):\n",
    "            predictions = np.array(predictions)\n",
    "        if not isinstance(labels, np.ndarray):\n",
    "            labels = np.array(labels)\n",
    "        \n",
    "        # 获取预测结果\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "        \n",
    "        # 计算指标\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
    "        precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
    "        recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
    "        \n",
    "        result = {\n",
    "            'accuracy': float(accuracy),\n",
    "            'f1': float(f1),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall)\n",
    "        }\n",
    "        \n",
    "        print(f\"Debug: computed metrics: {result}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_metrics: {e}\")\n",
    "        # 返回默认指标以避免训练中断\n",
    "        return {\n",
    "            'accuracy': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0\n",
    "        }\n",
    "\n",
    "# 6. Custom Trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs['labels']\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# 7. 修改后的Training Arguments - 使用更保守的设置\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    # 临时禁用最佳模型加载以避免指标问题\n",
    "    load_best_model_at_end=False,\n",
    "    # metric_for_best_model='eval_f1',  # 暂时注释掉\n",
    "    # greater_is_better=True,  # 暂时注释掉\n",
    "    fp16=True,\n",
    "    dataloader_drop_last=False,\n",
    "    # 确保评估数据集被使用\n",
    "    do_eval=True,\n",
    "    # 添加更多调试信息\n",
    "    report_to=None,  # 禁用wandb等报告\n",
    ")\n",
    "\n",
    "# 8. Initialize Trainer - 添加调试信息\n",
    "print(\"初始化Trainer...\")\n",
    "print(f\"训练数据集大小: {len(d_train)}\")\n",
    "print(f\"测试数据集大小: {len(d_test)}\")\n",
    "print(f\"数据集列: {d_train.column_names}\")\n",
    "\n",
    "# 检查数据集格式\n",
    "sample_batch = d_train[:2]\n",
    "print(f\"样本批次键: {sample_batch.keys()}\")\n",
    "for key, value in sample_batch.items():\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"{key} shape: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"{key} type: {type(value)}\")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=d_train,\n",
    "    eval_dataset=d_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 验证compute_metrics函数\n",
    "print(\"测试compute_metrics函数...\")\n",
    "try:\n",
    "    # 创建一个测试样本\n",
    "    test_logits = np.random.rand(4, num_labels)  # 4个样本，3个类别\n",
    "    test_labels = np.array([0, 1, 2, 1])\n",
    "    test_result = compute_metrics((test_logits, test_labels))\n",
    "    print(f\"compute_metrics测试成功: {test_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"compute_metrics测试失败: {e}\")\n",
    "\n",
    "# 9. Train\n",
    "print(\"开始训练...\")\n",
    "trainer.train()\n",
    "\n",
    "# 10. RAG Inference\n",
    "def rag_predict(texts, model, tokenizer, k=3):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for txt in texts:\n",
    "        context = retrieve_solutions(txt, k=k)\n",
    "        inp = tokenizer(f\"{txt} [CONTEXT] {context}\",\n",
    "                        return_tensors='pt',\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=128)\n",
    "        inp = {k: v.to('cuda') for k, v in inp.items()}\n",
    "        with torch.no_grad():\n",
    "            out = model(**inp)\n",
    "        pred = torch.argmax(out.logits, dim=-1).cpu().item()\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "# 11. 修复的评估部分\n",
    "print(\"开始评估...\")\n",
    "test_texts = test_df['text'].tolist()\n",
    "y_true = test_df['label'].tolist()\n",
    "\n",
    "# 使用RAG预测\n",
    "y_pred_rag = rag_predict(test_texts, model, tokenizer)\n",
    "\n",
    "# 计算指标\n",
    "accuracy = accuracy_score(y_true, y_pred_rag)\n",
    "f1 = f1_score(y_true, y_pred_rag, average='weighted')\n",
    "precision = precision_score(y_true, y_pred_rag, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_rag, average='weighted')\n",
    "\n",
    "print(\"RAG预测结果:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_true, y_pred_rag)\n",
    "print(\"\\n混淆矩阵:\")\n",
    "print(cm)\n",
    "\n",
    "# 按类别显示结果\n",
    "print(f\"\\n标签映射: {id_to_label}\")\n",
    "for i, label in id_to_label.items():\n",
    "    mask = np.array(y_true) == i\n",
    "    if mask.sum() > 0:\n",
    "        class_acc = accuracy_score(np.array(y_true)[mask], np.array(y_pred_rag)[mask])\n",
    "        print(f\"{label} 类准确率: {class_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qwen3DevOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
